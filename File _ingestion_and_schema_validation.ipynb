{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dddf720",
   "metadata": {},
   "source": [
    "# File ingestion and schema validation\n",
    "\n",
    "## Task:\n",
    "- Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "- Read the file ( Present approach of reading the file )\n",
    "- Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "- Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "- As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of read and write file, column name in YAML\n",
    "- Validate number of columns and column name of ingested file with YAML.\n",
    "- Write the file in pipe separated text file (|) in gz format.\n",
    "- Create a summary of the file:\n",
    "    - Total number of rows,\n",
    "    - total number of columns\n",
    "    - file size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc29de",
   "metadata": {},
   "source": [
    "# Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4cfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bc4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data file : 2859504349\n"
     ]
    }
   ],
   "source": [
    "# get the size of data file\n",
    "size = os.path.getsize(\"C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv\")\n",
    "print(f\"size of the data file : {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cb6d3",
   "metadata": {},
   "source": [
    "## Read the data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39ee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas:  35.50532031059265 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = time.time()\n",
    "df = pd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c78d2",
   "metadata": {},
   "source": [
    "## Read the data with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53dfbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  1.442429780960083 sec\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "start = time.time()\n",
    "df = dd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39b5f9",
   "metadata": {},
   "source": [
    "## Read the data with Modin and Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55d00f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 09:47:17,699\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with modin and ray:  33.37739181518555 sec\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "start = time.time()\n",
    "df = pd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with modin and ray: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9718a",
   "metadata": {},
   "source": [
    "## Read the data with Vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa14b03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vaex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvaex\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m vaex\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vaex'"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "start = time.time()\n",
    "df = vaex.open('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with vaex: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6662406",
   "metadata": {},
   "source": [
    "## Here Dask is better than Pandas, Modin and Ray, Vaex with the least reading time of aprroximate 0.87 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf23a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94211014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 10 entries, Id to review/text\n",
      "dtypes: object(6), float64(2), int64(2)"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfd3948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns :  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns : \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdb0255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
       "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a2badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\AppData\\Local\\Temp\\ipykernel_11844\\1735410971.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[ ,/,&,#,@,_,-]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'Userid', 'profileName', 'reviewhelpfulness',\n",
       "       'reviewscore', 'reviewtime', 'reviewsummary', 'reviewtext'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace('[ ,/,&,#,@,_,-]','')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a858c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'price', 'userid', 'profilename', 'reviewhelpfulness',\n",
       "       'reviewscore', 'reviewtime', 'reviewsummary', 'reviewtext'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9344fc",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004a6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import datetime \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60373c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "396f275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = utility.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "276ad420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['inbound_delimiter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "962c0e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'datset_name': 'testfile',\n",
       " 'file_name': 'Books_rating',\n",
       " 'table_name': 'edusurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['id',\n",
       "  'title',\n",
       "  'price',\n",
       "  'userid',\n",
       "  'profilename',\n",
       "  'reviewhelpfulness',\n",
       "  'reviewscore',\n",
       "  'reviewtime',\n",
       "  'reviewsummary',\n",
       "  'reviewtext']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting data of config file\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc086edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: Could not interpret '1,' as a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\utils.py\u001b[0m in \u001b[0;36mparse_bytes\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '1,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\backends.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m     ):\n\u001b[1;32m--> 756\u001b[1;33m         return read_pandas(\n\u001b[0m\u001b[0;32m    757\u001b[0m             \u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mblocksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblocksize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\utils.py\u001b[0m in \u001b[0;36mparse_bytes\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not interpret '%s' as a number\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret '1,' as a number",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11844\\1105371606.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msource_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inbound_delimiter'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\DataGlacier\\lib\\site-packages\\dask\\backends.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                     raise type(e)(\n\u001b[0m\u001b[0;32m    136\u001b[0m                         \u001b[1;34mf\"An error occurred while calling the {funcname(func)} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                         \u001b[1;34mf\"method registered to the {self.backend} backend.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: Could not interpret '1,' as a number"
     ]
    }
   ],
   "source": [
    "# read the file using config file\n",
    "#Reading the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"C:/Users/chitr/Documents/DataGlacier/Data/\" + config_data['file_name'] + f'.{file_type}'\n",
    "\n",
    "print(\"\",source_file)\n",
    "df = dd.read_csv(source_file,config_data['inbound_delimiter'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
