{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dddf720",
   "metadata": {},
   "source": [
    "# File ingestion and schema validation\n",
    "\n",
    "## Task:\n",
    "- Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "- Read the file ( Present approach of reading the file )\n",
    "- Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "- Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "- As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of read and write file, column name in YAML\n",
    "- Validate number of columns and column name of ingested file with YAML.\n",
    "- Write the file in pipe separated text file (|) in gz format.\n",
    "- Create a summary of the file:\n",
    "    - Total number of rows,\n",
    "    - total number of columns\n",
    "    - file size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc29de",
   "metadata": {},
   "source": [
    "# Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4cfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bc4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data file : 2859504349\n"
     ]
    }
   ],
   "source": [
    "# get the size of data file\n",
    "size = os.path.getsize(\"C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv\")\n",
    "print(f\"size of the data file : {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cb6d3",
   "metadata": {},
   "source": [
    "## Read the data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39ee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas:  35.40927815437317 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = time.time()\n",
    "df = pd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c78d2",
   "metadata": {},
   "source": [
    "## Read the data with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53dfbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.8652992248535156 sec\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "start = time.time()\n",
    "df = dd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39b5f9",
   "metadata": {},
   "source": [
    "## Read the data with Modin and Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55d00f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 10:27:23,369\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with modin and ray:  61.704468965530396 sec\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "start = time.time()\n",
    "df = pd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with modin and ray: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9718a",
   "metadata": {},
   "source": [
    "## Read the data with Vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa14b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with vaex:  6.6056108474731445 sec\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "start = time.time()\n",
    "df = vaex.open('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with vaex: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6662406",
   "metadata": {},
   "source": [
    "## Here Dask is better than Pandas, Modin and Ray, Vaex with the least reading time of aprroximate 0.87 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf23a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('C:/Users/chitr/Documents/DataGlacier/Data/Books_rating.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94211014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 10 entries, Id to review/text\n",
      "dtypes: object(6), float64(2), int64(2)"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfd3948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns :  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns : \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccdb0255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
       "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1a2badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'Userid', 'profileName', 'reviewhelpfulness',\n",
       "       'reviewscore', 'reviewtime', 'reviewsummary', 'reviewtext'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace('[ ,/,&,#,@,_,-]','')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66a858c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'price', 'userid', 'profilename', 'reviewhelpfulness',\n",
       "       'reviewscore', 'reviewtime', 'reviewsummary', 'reviewtext'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9344fc",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "004a6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef6557e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.load(stream, Loader=yaml.Loader)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbfbf7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting store.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile store.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: Books_Ratings\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - id\n",
    "    - title\n",
    "    - price\n",
    "    - userid\n",
    "    - profilename\n",
    "    - reviewhelpfulness\n",
    "    - reviewscore\n",
    "    - reviewtime\n",
    "    - reviewsummary\n",
    "    - reviewtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60373c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\DataGlacier\\Data_Ingestion_Pipeline\\utility.py:5\u001b[0m, in \u001b[0;36mread_config_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43myaml\u001b[49m\u001b[38;5;241m.\u001b[39mload(stream, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mYAMLError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaml' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read config file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutility\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m config_data \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DataGlacier\\Data_Ingestion_Pipeline\\utility.py:6\u001b[0m, in \u001b[0;36mread_config_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mload(stream, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43myaml\u001b[49m\u001b[38;5;241m.\u001b[39mYAMLError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m      7\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(exc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "# Read config file\n",
    "import utility as util\n",
    "config_data = util.read_config_file(\"store.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
